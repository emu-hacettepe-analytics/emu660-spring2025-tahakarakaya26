[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Taha Karakaya.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project X",
    "section": "",
    "text": "Welcome to my project page.\nKeep an eye on this space to stay updated with my project activities.\n(The titles below are provided as examples; please feel free to adjust them as necessary.)"
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project X",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nxxxxxx"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project X",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nxxxxxx"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project X",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nxxxxxx"
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project X",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nxxxxxx"
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project X",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project X",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project X",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project X",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the Spring 2024-2025 EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nAselsan, Workshop Planning Engineer, 07.2024 - ongoing"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nTurkish Aerospace Industries, Business Analyst Intern, Ankara, 07.2023 - 08.2023\nThe Ministry of Industry and Technology, Research Intern, Ankara, 08.2023 - 09.2023\nVispera Information Technologies, Data & Insight Analyst Intern, Remote, 09.2023 - 10.2023"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "A Beatiful Life in Poland\nYou can access the link: (https://medium.com/@ahmettaha736/erasmus-ya%C5%9Fam%C4%B1m-58ad1d0e6f20)\nHello there! If you’re reading this, I assume you already know what Erasmus is and are familiar with the process you have gone through or will be going through???so I wont be diving into that.\nInstead, I want to take a more specific and practical approach by sharing insights about the university I attended, the dorm I stayed in, and the trips I took. Before my own Erasmus experience, I found reading structured, bullet-pointed experiences more useful, so my writing will follow the same format.\nEDUCATION I did my Erasmus during the Spring semester of 2021-2022 at Lodz University, located in Lodz, Poland. Even though COVID-19 had lost much of its impact by then, the university decided to continue with online classes. I took a total of five courses and matched all of them as elective courses at my home university, Hacettepe University. I passed four of them (as for the one I did not lets just say the professors incompetence played a big role. He did not even show up to classes).\nIn general, the courses were very relaxed, nothing like the intense academic pressure we are used to in Turkey. There is only one exam, and to be honest, you would have to actively try to fail. All the courses were in English, so from an educational and course-matching perspective, Poland gets a solid score from me: 9/10.\nGENERAL LIFE Lodz used to be an industrial city back in the day, and while it has developed in that regard, it still has its limit. As someone born and raised in Ankara, I found it a bit underwhelming. There was not much to do, and the university itself had a scattered campus structure, meaning that different faculties were located all over the city. This was a big downside for me because one of the main reasons I chose Hacettepe University was its centralized campus. Due to this, finding extracurricular activities like sports clubs or hobby groups was quite difficult. Without Erasmus groups organizing social events, competitions, and evening activities, life would have been very monotonous.\nWhen it comes to the people, I must say that locals around our age were very friendly and warm-hearted. I received so much help from them, and they were truly wonderful people. However, for those 30 and above, I encountered the same issues I have seen across Europe: language barriers and a certain level of social distance toward foreigners. While I would not call it discrimination, they certainly were not as welcoming as the younger generation. I believe this is more of a cultural difference than anything else. After spending five months living in, eating in, and breathing in this city, I do not want to be unfairly critical, but the overall atmosphere, both in terms of weather and people, was quite cold. It just is what it is. 7/10.\nTRAVEL Now, let???s move on to the most exciting part! I love saying this out loud: Despite the economic downturn, despite the global inflation crisis, I managed to visit 12 countries and 25 cities! And in 10 countries and 18 cities, I truly immersed myself in the culture.\nEveryone has a primary goal when they go on Erasmus. Mine was travel. This was my first time traveling around Europe, and I checked off nearly every place I had ever dreamed of visiting. In fact, I loved some of them so much that I went back two or three times!\nAnd it was incredible. Swimming in the sea in Barcelona. Joining a historic Pride march in Bologna, the “Red City” Experiencing techno clubs in Berlin??? Trying every legal indulgence Amsterdam had to offer. Sipping espresso in every hidden corner of Rome (I have not touched instant coffee since that trip!)\nIt was truly, beyond words, amazing.\nBut of course, no experience is perfect. Despite my efforts to blend in, I often faced language barriers and not due to a lack of effort on my part! I can get by with basic Spanish, and I am very confident in my English, but if you do not speak the local language, you might be treated as an outsider, almost like an intruder. And lets be honest many of us in Turkey have probably seen this behavior from the opposite perspective as well. It is uncomfortable. And to face this while studying abroad, after earning your spot through hard work and dedication, is even more frustrating. Consider this a small warning do not be surprised if you run into this.\nLooking at the bigger picture, from sleeping under the Eiffel Tower to crashing in train stations, airports, and bus terminals, travel was a constant adventure, with every moment teaching me something new. My final rating is 10/10. If I had the chance, I would do it all over again.\nLife is short, do not put off the places you want to see and the lives you want to experience. Be a bird, spread your wings, and fly.\nSUMMARY Poland is a beautiful country. And living in Europe is an eye-opening experience. But deep down, I wish my own country could offer the same level of freedom, economy, and opportunities. I wish we could truly live, thrive, and say “Yes, I have a great life here.”\nLets keep pushing forward, in the spirit of our nations founding principles, and truly invest in ourselves. Because if we do not do it, no one else will.\nFor those who did not get accepted into Erasmus, do not be discouraged, there are other exchange programs out there, so keep trying. And for those who did get in congratulations! I wish you an unforgettable Erasmus experience, from the bottom of my heart.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/assignments/assignment-1.html",
    "href": "docs/assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts."
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts."
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": ".profile-pic { border-radius: 50%; width: 200px; /* ??stedi??in geni??lik / height: 200px; / Orant??l?? yapmak i??in ayn?? y??kseklik / object-fit: cover; / Foto??raf??n oranlar??n?? koruyarak k??rpmas??n?? sa??lar */ display: block; margin: auto; }"
  },
  {
    "objectID": "assignments/assignment-1.html#youtube-konusmasi",
    "href": "assignments/assignment-1.html#youtube-konusmasi",
    "title": "Assignment 1",
    "section": "(Youtube Konusmasi)",
    "text": "(Youtube Konusmasi)"
  },
  {
    "objectID": "assignments/assignment-1.html#veri-analizi",
    "href": "assignments/assignment-1.html#veri-analizi",
    "title": "Assignment 1",
    "section": "(Veri Analizi)",
    "text": "(Veri Analizi)"
  },
  {
    "objectID": "assignments/assignment-1.html#na-doldurma",
    "href": "assignments/assignment-1.html#na-doldurma",
    "title": "Assignment 1",
    "section": "(NA Doldurma)",
    "text": "(NA Doldurma)"
  },
  {
    "objectID": "assignments/assignment-1.html#veri-bilimi-ve-endstri-mhendislii-zerine-sohbetler--kerem-demirta-erdi-dademir",
    "href": "assignments/assignment-1.html#veri-bilimi-ve-endstri-mhendislii-zerine-sohbetler--kerem-demirta-erdi-dademir",
    "title": "Assignment 1",
    "section": "(Veri Bilimi ve End??stri M??hendisli??i ??zerine Sohbetler -Kerem Demirta?? & Erdi Da??demir)",
    "text": "(Veri Bilimi ve End??stri M??hendisli??i ??zerine Sohbetler -Kerem Demirta?? & Erdi Da??demir)\n#The Integration of Industrial Engineering and Data Science: A Key to Smarter Decision-Making The integration of industrial engineering (IE) and data science (DS) is becoming increasingly important in today’s business world. This discussion particularly focused on how industrial engineers can enhance their analytical skills and transition into the field of data science. The relationship between traditional optimization techniques and machine learning was explored, highlighting that deterministic modeling methods may fall short in highly variable and uncertain environments. As a result, data-driven approaches such as event-based simulation, probabilistic modeling, and statistical learning are gaining more significance. It was also emphasized that essential competencies for industrial engineers in this field include proficiency in SQL, Python, and statistical analysis tools. Data-driven decision support systems have the potential to solve traditional industrial engineering problems???such as supply chain management, logistics, and inventory optimization???much more efficiently.\nMoreover, it was underscored that theoretical knowledge alone is not sufficient; working on real-world problems is essential. Platforms like Kaggle provide valuable opportunities to develop hands-on projects, connect with professionals in the field, and focus on industry-specific challenges, all of which are crucial for career development. For instance, an industrial engineer applying data science to demand forecasting, production planning, or operational efficiency can gain a significant competitive edge. Many conventional engineering problems can now be enhanced using machine learning-based forecasting models, time series analysis, and big data solutions, ultimately leading to smarter and more optimized processes. Lastly, the discussion emphasized that industrial engineers should not only focus on developing models but also understand business processes, accurately define problems, and implement strategic, optimized solutions.\n#Personal Takeaways and Career Development As a recent graduate working in planning operations, I have had the opportunity to closely observe the growing importance of integrating data science into business processes. Through this experience, I have realized the critical role of data analytics and automation tools in strengthening decision support systems. To enhance efficiency in reporting processes, I have been improving my automation skills while also leveraging predictive models to support strategic decision-making. Moving forward, I aim to further develop my expertise in statistical analysis, machine learning, and optimization techniques to create added value in business processes."
  },
  {
    "objectID": "assignments/assignment-1.html#discussion-on-data-science-and-industrial-engineering---kerem-demirta-erdi-dademir",
    "href": "assignments/assignment-1.html#discussion-on-data-science-and-industrial-engineering---kerem-demirta-erdi-dademir",
    "title": "Assignment 1",
    "section": "(Discussion on Data Science and Industrial Engineering - Kerem Demirta?? & Erdi Da??demir)",
    "text": "(Discussion on Data Science and Industrial Engineering - Kerem Demirta?? & Erdi Da??demir)\n#The Integration of Industrial Engineering and Data Science: A Key to Smarter Decision-Making The integration of industrial engineering (IE) and data science (DS) is becoming increasingly important in today’s business world. This discussion particularly focused on how industrial engineers can enhance their analytical skills and transition into the field of data science. The relationship between traditional optimization techniques and machine learning was explored, highlighting that deterministic modeling methods may fall short in highly variable and uncertain environments. As a result, data-driven approaches such as event-based simulation, probabilistic modeling, and statistical learning are gaining more significance. It was also emphasized that essential competencies for industrial engineers in this field include proficiency in SQL, Python, and statistical analysis tools. Data-driven decision support systems have the potential to solve traditional industrial engineering problems???such as supply chain management, logistics, and inventory optimization???much more efficiently.\nMoreover, it was underscored that theoretical knowledge alone is not sufficient; working on real-world problems is essential. Platforms like Kaggle provide valuable opportunities to develop hands-on projects, connect with professionals in the field, and focus on industry-specific challenges, all of which are crucial for career development. For instance, an industrial engineer applying data science to demand forecasting, production planning, or operational efficiency can gain a significant competitive edge. Many conventional engineering problems can now be enhanced using machine learning-based forecasting models, time series analysis, and big data solutions, ultimately leading to smarter and more optimized processes. Lastly, the discussion emphasized that industrial engineers should not only focus on developing models but also understand business processes, accurately define problems, and implement strategic, optimized solutions.\n#Personal Takeaways and Career Development As a recent graduate working in planning operations, I have had the opportunity to closely observe the growing importance of integrating data science into business processes. Through this experience, I have realized the critical role of data analytics and automation tools in strengthening decision support systems. To enhance efficiency in reporting processes, I have been improving my automation skills while also leveraging predictive models to support strategic decision-making. Moving forward, I aim to further develop my expertise in statistical analysis, machine learning, and optimization techniques to create added value in business processes."
  },
  {
    "objectID": "assignments/assignment-1.html#discussion-on-data-science-and-industrial-engineering---kerem-demirtas-erdi-dasdemir",
    "href": "assignments/assignment-1.html#discussion-on-data-science-and-industrial-engineering---kerem-demirtas-erdi-dasdemir",
    "title": "Assignment 1",
    "section": "(Discussion on Data Science and Industrial Engineering - Kerem Demirtas & Erdi Dasdemir)",
    "text": "(Discussion on Data Science and Industrial Engineering - Kerem Demirtas & Erdi Dasdemir)\n\nThe Integration of Industrial Engineering and Data Science: A Key to Smarter Decision-Making\nThe integration of industrial engineering (IE) and data science (DS) is becoming increasingly important in today’s business world. This discussion particularly focused on how industrial engineers can enhance their analytical skills and transition into the field of data science. The relationship between traditional optimization techniques and machine learning was explored, highlighting that deterministic modeling methods may fall short in highly variable and uncertain environments. As a result, data-driven approaches such as event-based simulation, probabilistic modeling, and statistical learning are gaining more significance. It was also emphasized that essential competencies for industrial engineers in this field include proficiency in SQL, Python, and statistical analysis tools. Data-driven decision support systems have the potential to solve traditional industrial engineering problems???such as supply chain management, logistics, and inventory optimization???much more efficiently.\nMoreover, it was underscored that theoretical knowledge alone is not sufficient; working on real-world problems is essential. Platforms like Kaggle provide valuable opportunities to develop hands-on projects, connect with professionals in the field, and focus on industry-specific challenges, all of which are crucial for career development. For instance, an industrial engineer applying data science to demand forecasting, production planning, or operational efficiency can gain a significant competitive edge. Many conventional engineering problems can now be enhanced using machine learning-based forecasting models, time series analysis, and big data solutions, ultimately leading to smarter and more optimized processes. Lastly, the discussion emphasized that industrial engineers should not only focus on developing models but also understand business processes, accurately define problems, and implement strategic, optimized solutions.\n\n\nPersonal Takeaways and Career Development\nAs a recent graduate working in planning operations, I have had the opportunity to closely observe the growing importance of integrating data science into business processes. Through this experience, I have realized the critical role of data analytics and automation tools in strengthening decision support systems. To enhance efficiency in reporting processes, I have been improving my automation skills while also leveraging predictive models to support strategic decision-making. Moving forward, I aim to further develop my expertise in statistical analysis, machine learning, and optimization techniques to create added value in business processes."
  },
  {
    "objectID": "assignments/assignment-1.html#a-discussion-on-data-science-and-industrial-engineering---kerem-demirtas-erdi-dasdemir",
    "href": "assignments/assignment-1.html#a-discussion-on-data-science-and-industrial-engineering---kerem-demirtas-erdi-dasdemir",
    "title": "Assignment 1",
    "section": "a) Discussion on Data Science and Industrial Engineering - Kerem Demirtas & Erdi Dasdemir",
    "text": "a) Discussion on Data Science and Industrial Engineering - Kerem Demirtas & Erdi Dasdemir\nYou can access the related discussion through this link. (https://www.youtube.com/watch?v=cUPtQEyaswM)\n\nThe Integration of Industrial Engineering and Data Science: A Key to Smarter Decision-Making\nThe integration of industrial engineering (IE) and data science (DS) is becoming increasingly important in today’s business world. This discussion particularly focused on how industrial engineers can enhance their analytical skills and transition into the field of data science. The relationship between traditional optimization techniques and machine learning was explored, highlighting that deterministic modeling methods may fall short in highly variable and uncertain environments. As a result, data-driven approaches such as event-based simulation, probabilistic modeling, and statistical learning are gaining more significance. It was also emphasized that essential competencies for industrial engineers in this field include proficiency in SQL, Python, and statistical analysis tools. Data-driven decision support systems have the potential to solve traditional industrial engineering problems—such as supply chain management, logistics, and inventory optimization—much more efficiently.\nMoreover, it was underscored that theoretical knowledge alone is not sufficient; working on real-world problems is essential. Platforms like Kaggle provide valuable opportunities to develop hands-on projects, connect with professionals in the field, and focus on industry-specific challenges, all of which are crucial for career development. For instance, an industrial engineer applying data science to demand forecasting, production planning, or operational efficiency can gain a significant competitive edge. Many conventional engineering problems can now be enhanced using machine learning-based forecasting models, time series analysis, and big data solutions, ultimately leading to smarter and more optimized processes. Lastly, the discussion emphasized that industrial engineers should not only focus on developing models but also understand business processes, accurately define problems, and implement strategic, optimized solutions.\n\n\nPersonal Takeaways and Career Development\nAs a recent graduate working in planning operations, I have had the opportunity to closely observe the growing importance of integrating data science into business processes. Through this experience, I have realized the critical role of data analytics and automation tools in strengthening decision support systems. To enhance efficiency in reporting processes, I have been improving my automation skills while also leveraging predictive models to support strategic decision-making. Moving forward, I aim to further develop my expertise in statistical analysis, machine learning, and optimization techniques to create added value in business processes."
  },
  {
    "objectID": "assignments/assignment-1.html#b-veri-analizi",
    "href": "assignments/assignment-1.html#b-veri-analizi",
    "title": "Assignment 1",
    "section": "b) (Veri Analizi)",
    "text": "b) (Veri Analizi)\n\nlibrary(dslabs)\ndata(na_example)\nna_example\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2"
  },
  {
    "objectID": "assignments/assignment-1.html#c-na-doldurma",
    "href": "assignments/assignment-1.html#c-na-doldurma",
    "title": "Assignment 1",
    "section": "c) (NA Doldurma)",
    "text": "c) (NA Doldurma)\n\nlibrary(dslabs)\ndata(na_example)\nna_example\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2"
  },
  {
    "objectID": "assignments/assignment-1.html#b-statistical-summaries-with-custom-functions-and-iteration-methods-in-mtcars-dataset",
    "href": "assignments/assignment-1.html#b-statistical-summaries-with-custom-functions-and-iteration-methods-in-mtcars-dataset",
    "title": "Assignment 1",
    "section": "b) Statistical Summaries with Custom Functions and Iteration Methods in mtcars dataset:",
    "text": "b) Statistical Summaries with Custom Functions and Iteration Methods in mtcars dataset:\n\nimport data\n\ndata(mtcars)\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\ndiscover the mtcars dataset\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\n\n\ncompute_stats\n\ncompute_stats &lt;- function(x) {\n  stats &lt;- list(\n    mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    variance = var(x, na.rm = TRUE),\n    iqr = IQR(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE)\n  )\n  return(stats)\n}\n\n\n\ndf of compute_stats\n\ncompute_stats &lt;- function(x) {\n  stats &lt;- list(\n    mean = mean(x, na.rm = TRUE),\n    median = median(x, na.rm = TRUE),\n    variance = var(x, na.rm = TRUE),\n    iqr = IQR(x, na.rm = TRUE),\n    min = min(x, na.rm = TRUE),\n    max = max(x, na.rm = TRUE)\n  )\n  return(stats)\n}\n\nstats_df &lt;- data.frame(Column = character(),\n                       Mean = numeric(),\n                       Median = numeric(),\n                       Variance = numeric(),\n                       IQR = numeric(),\n                       Min = numeric(),\n                       Max = numeric(),\n                       stringsAsFactors = FALSE)\n\nfor (col in names(mtcars)) {\n  \n  if (is.numeric(mtcars[[col]])) {\n    \n    stats &lt;- compute_stats(mtcars[[col]])\n    \n    new_row &lt;- data.frame(Column = col,\n                          Mean = stats$mean,\n                          Median = stats$median,\n                          Variance = stats$variance,\n                          IQR = stats$iqr,\n                          Min = stats$min,\n                          Max = stats$max,\n                          stringsAsFactors = FALSE)\n    \n    stats_df &lt;- rbind(stats_df, new_row)\n  }\n}\n\nlibrary(knitr)\nkable(stats_df, caption = \"Stats Df\")\n\n\nStats Df\n\n\nColumn\nMean\nMedian\nVariance\nIQR\nMin\nMax\n\n\n\n\nmpg\n20.090625\n19.200\n3.632410e+01\n7.37500\n10.400\n33.900\n\n\ncyl\n6.187500\n6.000\n3.189516e+00\n4.00000\n4.000\n8.000\n\n\ndisp\n230.721875\n196.300\n1.536080e+04\n205.17500\n71.100\n472.000\n\n\nhp\n146.687500\n123.000\n4.700867e+03\n83.50000\n52.000\n335.000\n\n\ndrat\n3.596563\n3.695\n2.858814e-01\n0.84000\n2.760\n4.930\n\n\nwt\n3.217250\n3.325\n9.573790e-01\n1.02875\n1.513\n5.424\n\n\nqsec\n17.848750\n17.710\n3.193166e+00\n2.00750\n14.500\n22.900\n\n\nvs\n0.437500\n0.000\n2.540323e-01\n1.00000\n0.000\n1.000\n\n\nam\n0.406250\n0.000\n2.489919e-01\n1.00000\n0.000\n1.000\n\n\ngear\n3.687500\n4.000\n5.443548e-01\n1.00000\n3.000\n5.000\n\n\ncarb\n2.812500\n2.000\n2.608871e+00\n2.00000\n1.000\n8.000\n\n\n\n\n\n\n\nwith sapply\n\ndata(mtcars)\ncompute_stats &lt;- function(x) {\n  c(Mean = mean(x, na.rm = TRUE),\n    Median = median(x, na.rm = TRUE),\n    Variance = var(x, na.rm = TRUE),\n    IQR = IQR(x, na.rm = TRUE),\n    Min = min(x, na.rm = TRUE),\n    Max = max(x, na.rm = TRUE))\n}\nstats_matrix &lt;- sapply(mtcars, compute_stats)\nstats_df &lt;- as.data.frame(t(stats_matrix))\nstats_df &lt;- cbind(Column = rownames(stats_df), stats_df)\nrownames(stats_df) &lt;- NULL\n\nlibrary(knitr)\nkable(stats_df, caption = \"Stats Df\")\n\n\nStats Df\n\n\nColumn\nMean\nMedian\nVariance\nIQR\nMin\nMax\n\n\n\n\nmpg\n20.090625\n19.200\n3.632410e+01\n7.37500\n10.400\n33.900\n\n\ncyl\n6.187500\n6.000\n3.189516e+00\n4.00000\n4.000\n8.000\n\n\ndisp\n230.721875\n196.300\n1.536080e+04\n205.17500\n71.100\n472.000\n\n\nhp\n146.687500\n123.000\n4.700867e+03\n83.50000\n52.000\n335.000\n\n\ndrat\n3.596563\n3.695\n2.858814e-01\n0.84000\n2.760\n4.930\n\n\nwt\n3.217250\n3.325\n9.573790e-01\n1.02875\n1.513\n5.424\n\n\nqsec\n17.848750\n17.710\n3.193166e+00\n2.00750\n14.500\n22.900\n\n\nvs\n0.437500\n0.000\n2.540323e-01\n1.00000\n0.000\n1.000\n\n\nam\n0.406250\n0.000\n2.489919e-01\n1.00000\n0.000\n1.000\n\n\ngear\n3.687500\n4.000\n5.443548e-01\n1.00000\n3.000\n5.000\n\n\ncarb\n2.812500\n2.000\n2.608871e+00\n2.00000\n1.000\n8.000"
  },
  {
    "objectID": "assignments/assignment-1.html#c-dslabs-missing-values",
    "href": "assignments/assignment-1.html#c-dslabs-missing-values",
    "title": "Assignment 1",
    "section": "c) dslabs, missing values",
    "text": "c) dslabs, missing values\n\nlibrary(dslabs)\ndata(na_example)\nna_example\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\nhow many? where?\n\nna_count &lt;- sum(is.na(na_example))\ncat(\"Number of total NA:\", na_count, \"\\n\")\n\nNumber of total NA: 145 \n\nna_indices &lt;- which(is.na(na_example))\ncat(\"Indices of NA values:\", na_indices, \"\\n\")\n\nIndices of NA values: 12 17 27 50 51 52 59 65 66 68 91 117 125 126 127 128 139 140 141 142 153 158 168 169 172 179 189 190 203 205 207 208 212 214 237 241 243 244 253 257 265 267 269 279 282 287 290 298 310 325 326 330 341 348 361 374 392 395 397 407 410 437 443 446 461 468 470 490 496 505 527 536 539 553 561 576 578 589 599 603 609 616 618 620 630 633 636 641 652 653 666 667 668 677 680 687 691 695 701 726 734 735 736 745 746 747 748 751 756 762 767 788 789 807 821 826 832 838 843 844 845 849 850 853 859 869 887 892 893 906 909 911 918 924 925 939 943 950 962 965 966 968 979 990 999 \n\n\n\n\nmean and std calculations except NA values\n\ndata(\"na_example\")\nmean_original &lt;- mean(na_example, na.rm = TRUE)\nsd_original &lt;- sd(na_example, na.rm = TRUE)\n\ncat(\"Data except NA's - Mean:\", mean_original, \"\\n\")\n\nData except NA's - Mean: 2.301754 \n\ncat(\"Data except NA's - Standard Deviation:\", sd_original, \"\\n\")\n\nData except NA's - Standard Deviation: 1.22338 \n\n\n\n\nhandling missing values, version 1, replacing with median\n\ndata(\"na_example\")\nmedian_value &lt;- median(na_example, na.rm = TRUE)\nna_median_filled &lt;- ifelse(is.na(na_example), median_value, na_example)\n\nmean_median &lt;- mean(na_median_filled)\nsd_median &lt;- sd(na_median_filled)\n\ncat(\"data of replaced with median --- mean:\", mean_median, \"\\n\")\n\ndata of replaced with median --- mean: 2.258 \n\ncat(\"data of replaced with median --- std:\", sd_median, \"\\n\")\n\ndata of replaced with median --- std: 1.136102 \n\n\n\n\nhandling missing values, version 2, replacing with random values\n\ndata(\"na_example\")\nna_fixed_filled &lt;- ifelse(is.na(na_example), 5, na_example)\n\nmean_fixed &lt;- mean(na_fixed_filled)\nsd_fixed &lt;- sd(na_fixed_filled)\n\ncat(\"data of replaced with fixed value (5) --- mean:\", mean_fixed, \"\\n\")\n\ndata of replaced with fixed value (5) --- mean: 2.693 \n\ncat(\"data of replaced with fixed value (5) --- std:\", sd_fixed, \"\\n\")\n\ndata of replaced with fixed value (5) --- std: 1.477476 \n\n\n\n\ncomparing results\n\ncomparison_df &lt;- data.frame(\n  Dataset = c(\"Original\", \"Median Filled\", \"Fixed Value (5)\"),\n  Mean = c(mean_original, mean_median, mean_fixed),\n  StD = c(sd_original, sd_median, sd_fixed)\n)\n\nlibrary(knitr)\nkable(comparison_df, caption = \"Comparison of Different NA Handling Methods\")\n\n\nComparison of Different NA Handling Methods\n\n\nDataset\nMean\nStD\n\n\n\n\nOriginal\n2.301754\n1.223380\n\n\nMedian Filled\n2.258000\n1.136102\n\n\nFixed Value (5)\n2.693000\n1.477475\n\n\n\n\n\n\n\nwhich method should be used? and why?\nFilling missing values with the median is generally a more reliable method because it is not affected by extreme outliers and better preserves the overall structure of the data.\nOn the other hand, filling with a randomly selected value may work better in certain scenarios, such as large-scale datasets, but it carries the risk of distorting the natural distribution of the data."
  }
]